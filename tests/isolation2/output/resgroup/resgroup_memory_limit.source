-- start_ignore
DROP VIEW IF EXISTS busy;
DROP
DROP VIEW IF EXISTS cancel_all;
DROP
DROP TABLE IF EXISTS bigtable;
DROP
DROP ROLE IF EXISTS role1_cpu_test;
DROP
DROP ROLE IF EXISTS role2_cpu_test;
DROP
DROP RESOURCE GROUP rg1_cpu_test;
DROP
DROP RESOURCE GROUP rg2_cpu_test;
DROP
DROP LANGUAGE IF EXISTS plpythonu;
DROP
CREATE EXTENSION plcontainer;
CREATE
CREATE LANGUAGE plpythonu;
CREATE
ALTER RESOURCE GROUP default_group SET memory_limit 1;
ALTER
ALTER RESOURCE GROUP admin_group SET memory_limit 10;
ALTER
-- end_ignore

-- plcontainer busy function.
CREATE OR REPLACE FUNCTION plbigmemory() RETURNS VOID AS $$ # container: plc_python_shared import time from subprocess import * p1 = Popen(["free", "-m"], stdout=PIPE) res = p1.communicate() mem_available = int(res[0].split("\n")[1].split()[-1]) ratio = 17113 / mem_available bytes_num = 100000000 * ratio f = ['d'] * bytes_num f[9] = 'c' f[1000000] = 'd' time.sleep(5) $$ LANGUAGE plcontainer;
CREATE

DROP TABLE IF EXISTS cpu_usage_samples;
DROP
CREATE TABLE cpu_usage_samples (sample text);
CREATE

-- fetch_sample: select cpu_usage from gp_toolkit.gp_resgroup_status
-- and dump them into text in json format then save them in db for
-- further analysis.
CREATE OR REPLACE FUNCTION fetch_sample() RETURNS text AS $$ import pygresql.pg as pg import json 
conn = pg.connect(dbname="isolation2resgrouptest") group_cpus = conn.query("select rsgname, cpu_usage from gp_toolkit.gp_resgroup_status")\ .getresult() json_text = json.dumps(dict([(name, json.loads(cpu)) for name, cpu in group_cpus])) sql = "insert into cpu_usage_samples values ('{value}')".format(value=json_text) conn.query(sql) return json_text $$ LANGUAGE plpythonu;
CREATE

-- verify_cpu_usage: calculate each QE's average cpu usage using all the data in
-- the table cpu_usage_sample. And compare the average value to the expected value.
-- return true if the practical value is close to the expected value.
CREATE OR REPLACE FUNCTION verify_cpu_usage(groupname TEXT, expect_cpu_usage INT, err_rate INT) RETURNS BOOL AS $$ import pygresql.pg as pg import json 
conn = pg.connect(dbname="isolation2resgrouptest") 
def add_vector(vec1, vec2): r = dict() for seg_id1, value1 in vec1.items(): r[seg_id1] = value1 + vec2[seg_id1] return r 

def verify_cpu_usage(): all_info = conn.query("select sample from cpu_usage_samples").getresult() usage_sum = reduce(add_vector, [json.loads(info)[groupname] for info, in all_info]) usage = [(float(v) / len(all_info)) for k, v in usage_sum.items() if k != "-1"] avg = sum(usage) / len(usage) return abs(avg - expect_cpu_usage) <= err_rate 
return verify_cpu_usage() $$ LANGUAGE plpythonu;
CREATE

CREATE TABLE bigtable AS SELECT i AS c1, 'abc' AS c2 FROM generate_series(1,50000) i;
CREATE 50000

CREATE TABLE smalltable(i int);
CREATE
insert into smalltable select generate_series(1,1000);
INSERT 1000

CREATE VIEW cancel_all AS SELECT pg_cancel_backend(procpid) FROM pg_stat_activity WHERE current_query LIKE 'SELECT * FROM busy%' or current_query LIKE 'SELECT plbusy%';
CREATE



CREATE TABLE a1(i int);
CREATE
insert into a1 values (1);
INSERT 1


ALTER RESOURCE GROUP admin_group SET cpu_rate_limit 1;
ALTER
-- ALTER RESOURCE GROUP admin_group SET cpu_rate_limit 30;
ALTER RESOURCE GROUP plgroup SET cpu_rate_limit 20;
ALTER

CREATE RESOURCE GROUP rg1_cpu_test WITH (concurrency=20, cpu_rate_limit=20, memory_limit=20);
CREATE
CREATE RESOURCE GROUP rg2_cpu_test WITH (concurrency=20, cpu_rate_limit=20, memory_limit=20);
CREATE
--
-- now we get prepared.
--
-- on empty load the cpu usage shall be 0%
--
-- create two roles and assign them to above groups
CREATE ROLE role1_cpu_test RESOURCE GROUP rg1_cpu_test;
CREATE
CREATE ROLE role2_cpu_test RESOURCE GROUP rg2_cpu_test;
CREATE
GRANT ALL ON plbigmemory TO role2_cpu_test;
ERROR:  relation "plbigmemory" does not exist
GRANT ALL ON a1 TO role2_cpu_test;
GRANT
GRANT ALL ON smalltable TO role1_cpu_test;
GRANT
GRANT ALL ON bigtable TO role1_cpu_test;
GRANT
-- prepare parallel queries in the two groups
8: SET ROLE TO role1_cpu_test;
SET
9: SET ROLE TO role1_cpu_test;
SET
10: SET ROLE TO role1_cpu_test;
SET
11: SET ROLE TO role1_cpu_test;
SET
12: SET ROLE TO role2_cpu_test;
SET
13: SET ROLE TO role2_cpu_test;
SET
14: SET ROLE TO role2_cpu_test;
SET
15: SET ROLE TO role2_cpu_test;
SET
16: SET ROLE TO role2_cpu_test;
SET
17: SET ROLE TO role2_cpu_test;
SET
18: SET ROLE TO role2_cpu_test;
SET
19: SET ROLE TO role2_cpu_test;
SET
20: SET ROLE TO role2_cpu_test;
SET
21: SET ROLE TO role2_cpu_test;
SET

8: SET optimizer = off;
SET
9: SET optimizer = off;
SET
10: SET optimizer = off;
SET
11: SET optimizer = off;
SET
12: SET optimizer = off;
SET
13: SET optimizer = off;
SET
14: SET optimizer = off;
SET
15: SET optimizer = off;
SET
16: SET optimizer = off;
SET
17: SET optimizer = off;
SET
18: SET optimizer = off;
SET
19: SET optimizer = off;
SET
20: SET optimizer = off;
SET
21: SET optimizer = off;
SET
--
-- a group should burst to use all the cpu usage
-- when it's the only one with running queries.
--
-- however the overall cpu usage is controlled by a GUC
-- gp_resource_group_cpu_limit which is 90% by default.
--
-- so the cpu usage shall be 90%
--

8&: select count(*) from bigtable t1, bigtable t2, smalltable where t1.c1 =t2.c1 and t1.c1>smalltable.i;  <waiting ...>
9&: select count(*) from bigtable t1, bigtable t2, smalltable where t1.c1 =t2.c1 and t1.c1>smalltable.i;  <waiting ...>
10&: select count(*) from bigtable t1, bigtable t2, smalltable where t1.c1 =t2.c1 and t1.c1>smalltable.i;  <waiting ...>
11&: select count(*) from bigtable t1, bigtable t2, smalltable where t1.c1 =t2.c1 and t1.c1>smalltable.i;  <waiting ...>
12&: SELECT plbigmemory() from a1;  <waiting ...>
13&: SELECT plbigmemory() from a1;  <waiting ...>
14&: SELECT plbigmemory() from a1;  <waiting ...>
15&: SELECT plbigmemory() from a1;  <waiting ...>
16&: SELECT plbigmemory() from a1;  <waiting ...>
17&: SELECT plbigmemory() from a1;  <waiting ...>
18&: SELECT plbigmemory() from a1;  <waiting ...>
19&: SELECT plbigmemory() from a1;  <waiting ...>
20&: SELECT plbigmemory() from a1;  <waiting ...>
21&: SELECT plbigmemory() from a1;  <waiting ...>
-- start_ignore
-- SELECT pg_sleep(10);
-- end_ignore

-- SELECT verify_cpu_usage('plgroup', 40, 10);

8<:  <... completed>
count   
--------
49499500
(1 row)
9<:  <... completed>
count   
--------
49499500
(1 row)
10<:  <... completed>
count   
--------
49499500
(1 row)
11<:  <... completed>
count   
--------
49499500
(1 row)
-- start_ignore
12<:  <... completed>
ERROR:  plcontainer: Error receiving data from the client: -1. Maybe retry later. (plcontainer.c:254)  (seg0 slice1 127.0.0.1:25432 pid=582764) (cdbdisp.c:254)
13<:  <... completed>
plbigmemory
-----------
           
(1 row)
14<:  <... completed>
plbigmemory
-----------
           
(1 row)
15<:  <... completed>
plbigmemory
-----------
           
(1 row)
16<:  <... completed>
ERROR:  plcontainer: Error receiving data from the client: -1. Maybe retry later. (plcontainer.c:254)  (seg0 slice1 127.0.0.1:25432 pid=582800) (cdbdisp.c:254)
17<:  <... completed>
ERROR:  plcontainer: Error receiving data from the client: -1. Maybe retry later. (plcontainer.c:254)  (seg0 slice1 127.0.0.1:25432 pid=582809) (cdbdisp.c:254)
18<:  <... completed>
plbigmemory
-----------
           
(1 row)
19<:  <... completed>
plbigmemory
-----------
           
(1 row)
20<:  <... completed>
plbigmemory
-----------
           
(1 row)
21<:  <... completed>
plbigmemory
-----------
           
(1 row)

ALTER RESOURCE GROUP rg1_cpu_test SET cpu_rate_limit 1;
ALTER
ALTER RESOURCE GROUP rg1_cpu_test SET memory_limit 1;
ALTER
ALTER RESOURCE GROUP rg2_cpu_test SET cpu_rate_limit 1;
ALTER
ALTER RESOURCE GROUP rg2_cpu_test SET memory_limit 1;
ALTER
-- end_ignore

